#  Medical Image Diffusion  
## Conditional DDPM for Chest X-ray Generation

This project implements a **class-conditional diffusion model (DDPM)** for **synthetic medical image generation**, applied to **Chest X-ray (CXR)** images from the NIH ChestX-ray dataset.

The objective is to generate **realistic chest radiographs conditioned on pathology labels**, with a focus on:
- medical data augmentation
- conditional generation
- reproducible research pipelines

The project is built with **PyTorch Lightning** and **Hugging Face Diffusers**, following best practices for medical ML (patient-level splits, leakage prevention, explicit conditioning).

---

##  Objectives
- Train a **conditional diffusion model** on medical images
- Generate realistic Chest X-rays **conditioned on specific pathologies**
- Explore diffusion models for **medical data augmentation**
- Address key challenges: class imbalance, label ambiguity, patient leakage

---

## Dataset

### NIH ChestX-ray14
- >100,000 frontal Chest X-rays
- Multi-label pathology annotations
- Patient-level identifiers

### Selected Labels (Single-label setup)
To simplify conditioning, only **single-label cases** are used.

| class_id | Label |
|--------:|------|
| 0 | No Finding |
| 1 | Atelectasis |
| 2 | Cardiomegaly |
| 3 | Effusion |
| 4 | Pneumonia |
| 5 | Pneumothorax |

Images with multiple simultaneous pathologies are filtered out.

---

##  Data Processing Pipeline
1. Parse raw label strings into binary columns
2. Normalize label names
3. Filter dataset to keep:
   - `No Finding` alone
   - or **exactly one pathology**
4. Create a `class_id` for conditional generation
5. Split data **at the patient level**:
   - 80% train
   - 10% validation
   - 10% test
6. Resolve image paths on disk
7. Save:
   - `metadata.parquet`
   - `train.csv`, `val.csv`, `test.csv`

This ensures **zero patient leakage** between splits.

---

##  Model Architecture

### Diffusion Model
- **DDPM (Denoising Diffusion Probabilistic Model)**
- Standard ε-prediction objective

### Backbone
- `UNet2DModel` (Hugging Face Diffusers)
- Input: **1 × 256 × 256** (grayscale)
- Multi-scale U-Net with attention blocks

### Conditioning Mechanism
- **Class embedding** (`num_class_embeds = 6`)
- Class information injected at every denoising step

---

## Training Objective

For each training step:
1. Sample a clean image `x₀`
2. Sample timestep `t`
3. Add Gaussian noise → `xₜ`
4. Predict noise `ε̂ = UNet(xₜ, t, class)`
5. Minimize Mean Squared Error:

\[
\mathcal{L} = \mathbb{E}_{x_0, \epsilon, t} \left[ \| \epsilon - \epsilon_\theta(x_t, t, y) \|^2 \right]
\]

---

##  Training Setup
- Optimizer: **AdamW**
- Learning rate: `1e-4`
- Scheduler: **CosineAnnealingLR**
- Image size: `256 × 256`
- Batch size: `8`
- Timesteps: `1000`
- Frameworks:
  - PyTorch Lightning
  - Hugging Face Diffusers
  - Hydra (config management)

---

##  Conditional Sampling

After training, images are generated by:
1. Sampling pure Gaussian noise
2. Iteratively denoising from `T → 0`
3. Conditioning on a fixed `class_id`

This allows controlled generation, e.g.:
- “Generate Chest X-rays with **Effusion**”
- “Generate healthy Chest X-rays”

---

##  Results

Observations:
- Coherent thoracic anatomy
- Realistic lung and cardiac structures
- Expected diffusion artifacts at early training stages

---

##  Limitations
- No classifier-free guidance (CFG) yet
- Single-label conditioning only
- No quantitative medical realism metrics (FID, radiologist evaluation)

---

##  Future Work
- Classifier-free guidance (CFG)
- Multi-label conditioning
- Higher resolution generation
- Quantitative evaluation (FID, LPIPS)
- Radiologist-in-the-loop validation
- Dataset balancing and reweighting
