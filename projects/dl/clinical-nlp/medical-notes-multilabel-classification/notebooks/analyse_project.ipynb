{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b3cbb3",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95045c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np \n",
    "import tqdm\n",
    "import torch\n",
    "parent_root = Path.cwd().parent\n",
    "project_root = os.path.join(parent_root, \"src\")\n",
    "sys.path.insert(0, str(project_root))\n",
    "from pytorch_lightning import seed_everything\n",
    "from accelerate import Accelerator\n",
    "import matplotlib.pyplot as plt\n",
    "import hydra\n",
    "\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra import compose, initialize_config_dir\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra import compose, initialize\n",
    "\n",
    "from datamodule import DataModule_nlp\n",
    "from clinicalbert_pl import Clinicalbert_pl\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86bde654",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"..\") / \"src\"\n",
    "data_dir = out_dir / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa81ed",
   "metadata": {},
   "source": [
    "# Def model / Datamodule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d320caf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "@hydra.main(config_path=\"config\", config_name=\"config_seg\", version_base=\"1.3\")\n",
    "def main(cfg: DictConfig):\n",
    "\n",
    "    seed_everything(cfg.get(\"seed\", 42), workers=True)\n",
    "\n",
    "    cfg_data = cfg.data\n",
    "    cfg_model = cfg.model\n",
    "\n",
    "    datamodule = DataModule_nlp(cfg_data)\n",
    "    model = Clinicalbert_pl(cfg_model)\n",
    "    return model, datamodule\n",
    "\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "config_path = os.path.join(out_dir, \"config\")\n",
    "\n",
    "with initialize(version_base=None, config_path=config_path, job_name=\"nb\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    model, datamodule = main(cfg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d77c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 126491/126491 [00:21<00:00, 6016.84 examples/s]\n",
      "Map: 100%|██████████| 15811/15811 [00:02<00:00, 5995.81 examples/s]\n",
      "Map: 100%|██████████| 15812/15812 [00:02<00:00, 6046.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "datamodule.setup(stage=\"test\")\n",
    "test_loader = datamodule.test_dataloader()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878af61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = out_dir / \"checkpoints/best.ckpt\"\n",
    "model = Clinicalbert_pl.load_from_checkpoint(\n",
    "    ckpt_path,\n",
    "    weights_only = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "391be389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clinicalbert_pl(\n",
       "  (model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       "  )\n",
       "  (loss_fn): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelerator = Accelerator(mixed_precision=\"bf16\")\n",
    "model = accelerator.prepare(\n",
    "    model\n",
    ")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12412d1b",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a86ed5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test eval: 100%|██████████| 321/321 [00:16<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_micro': 0.993259198832167, 'f1_macro': 0.9934201149211789, 'accuracy': 0.9907032633442955, 'probs_note': array([[2.7803096e-04, 4.5831289e-04, 1.0889691e-04, ..., 2.1654405e-04,\n",
      "        1.2339458e-04, 8.2958920e-04],\n",
      "       [2.3050673e-04, 5.8840885e-04, 1.3982208e-04, ..., 1.3982208e-04,\n",
      "        1.5843622e-04, 5.7031569e-04],\n",
      "       [3.8244836e-03, 3.1726826e-03, 2.1827165e-03, ..., 1.8102111e-03,\n",
      "        1.5978456e-03, 3.4834242e-03],\n",
      "       ...,\n",
      "       [2.3050673e-04, 3.3535014e-04, 1.0889691e-04, ..., 2.1654405e-04,\n",
      "        1.5843622e-04, 1.8102111e-03],\n",
      "       [8.2958920e-04, 9.1105117e-04, 4.5831289e-04, ..., 7.5540564e-04,\n",
      "        4.7285444e-04, 9.9566853e-01],\n",
      "       [5.5549247e-03, 6.2899021e-03, 5.9110685e-03, ..., 2.8009270e-03,\n",
      "        3.0753696e-03, 9.9193794e-01]], shape=(15812, 11), dtype=float32), 'y_true_note': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 1],\n",
      "       [0, 0, 0, ..., 0, 0, 1]], shape=(15812, 11), dtype=int32), 'label_names': ['diabetes', 'hypertension', 'asthma_copd', 'cad', 'heart_failure', 'ckd', 'depression_anxiety', 'obesity', 'cancer', 'stroke', 'infection']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "test_logits, test_labels, test_note_map = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(test_loader, desc=\"Test eval\"):\n",
    "        labels = batch.pop(\"labels\")\n",
    "        note_map = batch.pop(\"note_map\") # [B] mapping each chunk -> original note id (or index)\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        \n",
    "        test_logits.append(logits.detach().cpu())\n",
    "        test_labels.append(labels.detach().cpu())\n",
    "        test_note_map.append(note_map.detach().cpu())\n",
    "        \n",
    "logits = torch.cat(test_logits, dim=0)\n",
    "y_true = torch.cat(test_labels, dim=0).numpy()\n",
    "\n",
    "probs = torch.sigmoid(logits.float()).cpu().numpy()\n",
    "note_map = torch.cat(test_note_map, dim=0).numpy()\n",
    "unique_note = np.unique(note_map)\n",
    "C = probs.shape[1]\n",
    "\n",
    "probs_note = np.zeros((len(unique_note), C), dtype = np.float32)\n",
    "y_true_note = np.zeros((len(unique_note), C), dtype = np.int32)\n",
    "\n",
    "note_to_row = {nid : i for i, nid in enumerate(unique_note)}\n",
    "\n",
    "for i in range(probs.shape[0]):\n",
    "    r = note_to_row[note_map[i]]\n",
    "    probs_note[r] = np.maximum(probs_note[r], probs[i])\n",
    "    y_true_note[r] = np.maximum(y_true_note[r], y_true[i])\n",
    "    \n",
    "y_pred_note = (probs_note >= 0.5).astype(np.int32)\n",
    "f1_micro = f1_score(y_true_note, y_pred_note, average=\"micro\", zero_division=0)\n",
    "f1_macro = f1_score(y_true_note, y_pred_note, average=\"macro\", zero_division=0)\n",
    "subset_acc = accuracy_score(y_true_note, y_pred_note) \n",
    "\n",
    "with open(data_dir / \"label_names.txt\") as f:\n",
    "    label_names = [l.strip() for l in f.readlines()]        \n",
    "\n",
    "results = {\n",
    "    \"f1_micro\": float(f1_micro),\n",
    "    \"f1_macro\": float(f1_macro),\n",
    "    \"accuracy\": float(subset_acc),\n",
    "    \"probs_note\" : probs_note,\n",
    "    \"y_true_note\" : y_true_note,\n",
    "    \"label_names\" : label_names\n",
    "}\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da423bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_note_preds(\n",
    "    probs_note,\n",
    "    y_true_note,\n",
    "    label_names,\n",
    "    k=5,\n",
    "    threshold=0.5\n",
    "):\n",
    "    for i in range(k):\n",
    "        print(f\"\\nNOTE {i}\")\n",
    "        \n",
    "        true_labels = [\n",
    "            label_names[j]\n",
    "            for j in range(len(label_names))\n",
    "            if y_true_note[i, j] == 1\n",
    "        ]\n",
    "\n",
    "        pred_labels = [\n",
    "            f\"{label_names[j]} ({probs_note[i, j]:.2f})\"\n",
    "            for j in range(len(label_names))\n",
    "            if probs_note[i, j] >= threshold\n",
    "        ]\n",
    "\n",
    "        print(\"True:\", true_labels)\n",
    "        print(\"Pred:\", pred_labels)\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbe80779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE 0\n",
      "True: []\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "\n",
      "NOTE 1\n",
      "True: []\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "\n",
      "NOTE 2\n",
      "True: ['depression_anxiety']\n",
      "Pred: ['depression_anxiety (0.99)']\n",
      "--------------------------------------------------\n",
      "\n",
      "NOTE 3\n",
      "True: ['depression_anxiety', 'obesity']\n",
      "Pred: ['depression_anxiety (0.99)', 'obesity (0.99)']\n",
      "--------------------------------------------------\n",
      "\n",
      "NOTE 4\n",
      "True: ['cancer']\n",
      "Pred: ['cancer (1.00)']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_note_preds(results[\"probs_note\"], results[\"y_true_note\"], results[\"label_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c571142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_note(text, model, tokenizer, device):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    enc.pop(\"overflow_to_sample_mapping\", None)\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "        probs = torch.sigmoid(logits)\n",
    "    \n",
    "    probs_note = probs.max(dim=0).values\n",
    "    return probs_note.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a15839bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Patient with long history of type 2 diabetes and chronic hypertension...\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", use_fast=True)\n",
    "probs = predict_single_note(text, model, tokenizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67325475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes: 0.89\n",
      "hypertension: 0.95\n"
     ]
    }
   ],
   "source": [
    "for label, p in zip(results[\"label_names\"], probs):\n",
    "    if p >= 0.5:\n",
    "        print(f\"{label}: {p:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical-notes-multilabel-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
